{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9165b147-d04f-44c6-84d8-0da989a0c9be",
   "metadata": {},
   "source": [
    "# Explicando los embeddings\n",
    "\n",
    "¿Qué son los embeddings? ¿Cómo generarlos? ¿Qué hacer con ellos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07bbc669-2f6a-42df-8c3b-97d028ea1ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch torchvision sentence-transformers astrapy python-dotenv pandas ipywidgets -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0774cc0c",
   "metadata": {},
   "source": [
    "El paquete \"transformers\" provee miles de modelos pre-entrenados para realizar tareas de diferentes maodalidades como lo son texto, vision y audio. \n",
    "\n",
    "PyTorch es un paquete de Python que provee dos capacidades de alto nivel: \n",
    "* Cálculos con Tensores con aceleración usando GPU\n",
    "* Redes neuroanles \"profundas\" (deep neural networks) construidas sobre un sistema tape-based autograd\n",
    "\n",
    "El paquete torckvision consiste en datasets populares, arquitecturas modelo y transformaciones de imagen para computación visual. \n",
    "\n",
    "\"Sentence Transformers\" (llamado también SBERT) es un módulo de Python para usar y entrenar modelos de embedding novedosos. Puede ser usado para calcular embeddings usando modelos de Sentence Transformer or para calcular puntuaciones de similitud usando modelos Cross-encoder. \n",
    "\n",
    "Astrapy es el cliente de Python para usar la Data API de DataStax Astra. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845b761c",
   "metadata": {},
   "source": [
    "## Todo comienza con el tokenizado de una frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eed869-bcd9-4b6b-b6fd-e7e4f0fbbe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The world is full of kings and queens Who blind your eyes and steal your dreams It is Heaven and Hell\"\n",
    "# Black Sabbath - Heaven & Hell\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer_output = tokenizer.tokenize(sentence)\n",
    "print(tokenizer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f644f9f-c334-443d-8928-0a4417497f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_embedding = tokenizer.convert_tokens_to_ids(tokenizer_output)\n",
    "print(tokens_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c842989-68f5-4347-b9ff-1168201fee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_content = tokenizer.decode(tokens_embedding)\n",
    "print(decoded_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42df8b2-c3dd-47cc-8f80-33d718bc05da",
   "metadata": {},
   "source": [
    "\n",
    "## Los tokens no son los embeddings\n",
    "\n",
    "Pero esto todavía no es un emdedding. Simplemente es un relación de un token con un ID númerico.\n",
    "Los modelos parten de los tokens para iniciar el proseso a través de los transformres. Cada modelo tiene su propio proceso y es aquí donde se diferencian.\n",
    "\n",
    "# Generando embeddings\n",
    "\n",
    "(Código basado en el modelo: https://huggingface.co/intfloat/multilingual-e5-small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c3301-a4cc-4b50-b222-10a52032de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo comienza con la generación de tokens\n",
    "from transformers import  AutoTokenizer, AutoModel\n",
    "import json\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-small')\n",
    "tokens = tokenizer(sentence)\n",
    "print(f\"\"\"Tokens: {len(tokens[\"input_ids\"])}\"\"\")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601311b1-502d-4a6a-8635-ac9628a1355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando el modelo para generar el embedding\n",
    "model = AutoModel.from_pretrained('intfloat/multilingual-e5-small')\n",
    "batch_dict = tokenizer([sentence], max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "outputs = model(**batch_dict)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9db6e4-3a4d-4455-b37f-6890dfed6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3835c37d-2dea-41eb-aeec-4554266201b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling del resultado\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "def average_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea7097-e548-416a-9221-417f615a84c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92211e42-dbca-40c8-86c3-61b7f2e28101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize embeddings\n",
    "embeddings_norm = F.normalize(embeddings, p=2, dim=1)\n",
    "embeddings_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d8d57-4b6b-4250-99d0-ec8037afc95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_norm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ad70d-bb32-47e7-8b1a-e7ca19546b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('intfloat/multilingual-e5-small')\n",
    "input_texts = [\n",
    "    sentence\n",
    "]\n",
    "embedding_st = model.encode(input_texts, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3003e69-6bd3-4cd8-9b78-6f3823e2558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_st "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5377e0-0bb7-4506-90f7-d9d4dfa53f09",
   "metadata": {},
   "source": [
    "# ¿Qué hacemos con los Embeddings?\n",
    "\n",
    "Los embeddings son utilizados para encontrar contenido por su significado, en lugar de usar las palabras o términos específicamente. \n",
    "\n",
    "Vamos a ver en la práctica como generar, almacenar y encontrar similitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7026affc-b9e4-4eb9-8b63-71791999a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a importar los datos\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# df = pd.read_csv(\"./data/90minFootballTransferNewsNLP.csv\")\n",
    "\n",
    "# Load de dataset CSV \n",
    "df = pd.read_csv(\"data/ProductDataset.csv\", header = 0)\n",
    "#  new_df = pd.DataFrame(columns=['product_id','product_name', 'description', 'price', 'embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b353f2a7-9135-46df-8136-bbb9abe5eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "print(df.iloc[1][\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c5e236-12c5-433c-b936-6ebd0836967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model_emb = SentenceTransformer('intfloat/multilingual-e5-small')\n",
    "print(df.iloc[1][\"description\"])\n",
    "emb = model_emb.encode(df.iloc[1][\"description\"],normalize_embeddings=True)\n",
    "print(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1e288c",
   "metadata": {},
   "source": [
    "## Usar una base de datos para almacenar nuestros embeddings\n",
    "\n",
    "La base de datos para almacenar los embeddings debe contar con la capacidad de almacenar vectores y operar con ellos, como por ejemplo realizar una búsqueda vectorial. \n",
    "\n",
    "DataStax cuenta con las capacidades de una base de datos de Cassandra con la funcionalidad adicional de búsqueda de vectores.\n",
    "Vamos a usar una \"collection\" para almacenar nuestros embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b86160-57f1-49e7-a07d-3c9aedf259f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la conexión con DataStax Astra\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "import cassio\n",
    "from cqlsession import getCQLSession, getCQLKeyspace\n",
    "cqlMode = \"astra_db\" # \"astra_db\"/\"local\"\n",
    "session = getCQLSession(mode=cqlMode)\n",
    "keyspace = getCQLKeyspace(mode=cqlMode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d22e0-0c6a-40c5-b479-ac5dcb6c6486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este es el código para crear la tabla en Astra, pero usaremos coleeciones de datos en su lugar.\n",
    "\n",
    "from cassio.table.tables import MetadataVectorCassandraTable\n",
    "table_name = \"football_news_emb\"\n",
    "embedding_dimension = 384\n",
    "\n",
    "v_table = MetadataVectorCassandraTable(\n",
    "    session=session,\n",
    "    keyspace=keyspace,\n",
    "    table=table_name,\n",
    "    vector_dimension=embedding_dimension,\n",
    "    primary_key_type=\"TEXT\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a682e3e0-fc22-467f-9ccd-6251eb492552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "\n",
    "rows_to_load = 100\n",
    "for index, row in tqdm(df.head(rows_to_load).iterrows(),total=len(df.head(rows_to_load))):\n",
    "    v_table.put(\n",
    "            row_id=f\"\"\"{row[\"Date\"]}|{row[\"Title\"]}\"\"\",\n",
    "            body_blob=row[\"Content\"],\n",
    "            vector=model_emb.encode(row[\"Content\"]),\n",
    "            metadata={\"date\":row[\"Date\"], \"link\": row[\"Link\"]}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f5252",
   "metadata": {},
   "source": [
    "## Conexión usando la Data API de Astra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31594ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astrapy import DataAPIClient\n",
    "from dotenv import load_dotenv\n",
    "from astrapy.db import AstraDB, AstraDBCollection\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "coll_name = \"appliances\"\n",
    "embedding_dimension = 384\n",
    "\n",
    "print(\"AstraDB collection...\")\n",
    "\n",
    "client = DataAPIClient()\n",
    "database = client.get_database(\n",
    "    os.getenv(\"ASTRA_DB_API_ENDPOINT\"),\n",
    "    token=os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\"),\n",
    ")\n",
    "\n",
    "collection = database.create_collection(coll_name, dimension=embedding_dimension)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bd8325",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d35ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "\n",
    "rows_to_load = 10\n",
    "\n",
    "# Load to vector store\n",
    "def load_to_astra(df, collection):\n",
    "  #len_df = len(df)\n",
    "  len_df = rows_to_load\n",
    "\n",
    "  f = IntProgress(min=0, max=len_df) # instantiate the bar\n",
    "  display(f) # display the bar\n",
    "  for i in range(len_df):\n",
    "    f.value += 1 # signal to increment the progress bar\n",
    "    f.description = str(f.value) + \"/\" + str(len_df)\n",
    "\n",
    "    product_id = df.loc[i, \"product_id\"]\n",
    "    product_name = df.loc[i, \"product_name\"]\n",
    "    description = df.loc[i, \"description\"]\n",
    "    price = df.loc[i, \"price\"]\n",
    "    if(type(price) is float):\n",
    "      price = 0\n",
    "\n",
    "    # Vector elements are numpy.float32, which is not JSON serializable, .tolist() converts to native Python float\n",
    "    embedding = model_emb.encode(df.loc[i, \"description\"], normalize_embeddings=True).tolist() \n",
    "    \n",
    "    try:\n",
    "      #add to the Astra DB Vector Database\n",
    "      collection.insert_one({\n",
    "        \"_id\": str(product_id),\n",
    "        \"product_name\": product_name,\n",
    "        \"description\": description,\n",
    "        \"price\": price,\n",
    "        \"$vector\": embedding,\n",
    "        })\n",
    "    except Exception as error:\n",
    "      #if you've already added this record, skip the error message\n",
    "      if str(error) == \"Document already exists with the given _id\":\n",
    "        print(\"Document already exists in the database. Skipping.\")\n",
    "\n",
    "load_to_astra(df, collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebd01dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(collection.count_documents(filter={}, upper_bound=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766f9c47",
   "metadata": {},
   "source": [
    "## Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a452b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_coll = \"appliances_nvidia\"\n",
    "vect_collection = database.get_collection(vectorize_coll)\n",
    "\n",
    "print(vect_collection.count_documents(filter={}, upper_bound=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "\n",
    "vectorize_coll = \"appliances_nvidia\"\n",
    "vect_collection = database.get_collection(vectorize_coll)\n",
    "\n",
    "rows_to_load = 2\n",
    "\n",
    "# Load using vectorize\n",
    "def load_with_vectorize(df, collection):\n",
    "  len_df = rows_to_load #len_df = len(df)\n",
    "\n",
    "  f = IntProgress(min=0, max=len_df) # instantiate the bar\n",
    "  display(f) # display the bar\n",
    "  for i in range(len_df):\n",
    "    f.value += 1 # signal to increment the progress bar\n",
    "    f.description = str(f.value) + \"/\" + str(len_df)\n",
    "\n",
    "    product_id = df.loc[i, \"product_id\"]\n",
    "    product_name = df.loc[i, \"product_name\"]\n",
    "    description = df.loc[i, \"description\"]\n",
    "    price = df.loc[i, \"price\"]\n",
    "    if(type(price) is float):\n",
    "      price = 0\n",
    "    \n",
    "    try:\n",
    "      #add to the Astra DB Vector Database\n",
    "      collection.insert_one({\n",
    "        \"product_id\": str(product_id),\n",
    "        \"product_name\": product_name,\n",
    "        \"description\": description,\n",
    "        \"price\": price,\n",
    "        \"$vectorize\": product_name + \": \" +description,\n",
    "        })\n",
    "    except Exception as error:\n",
    "      #if you've already added this record, skip the error message\n",
    "      if str(error) == \"Document already exists with the given _id\":\n",
    "        print(\"Document already exists in the database. Skipping.\")\n",
    "\n",
    "load_with_vectorize(df, vect_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b90792d",
   "metadata": {},
   "source": [
    "## Búsqueda por similaridad de vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96efec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"reproductores de CD y DVD\"\n",
    "query_emb = model_emb.encode(query)\n",
    "\n",
    "results = collection.find(sort={\"$vector\": query_emb}, limit=5, include_similarity=True)\n",
    "for result in results:\n",
    "    print(\"--------------------\")\n",
    "    print(f\"\"\"Distance: {result[\"$similarity\"]}\"\"\")\n",
    "    print(f\"{result[\"product_name\"]} : {result[\"description\"]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
